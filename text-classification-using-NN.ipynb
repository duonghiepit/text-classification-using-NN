{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4659440",
   "metadata": {},
   "source": [
    "# I. Pytorch & Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59aa25c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Admin\\anaconda3\\envs\\basicNLPAIO\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install -q torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441d96fa-fbbb-4c2d-88e6-593ac5cd8e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torch-2.1.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.7 MB 1.5 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.3/5.7 MB 2.6 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.6/5.7 MB 4.0 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 1.1/5.7 MB 5.7 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 1.6/5.7 MB 7.2 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.1/5.7 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 2.7/5.7 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 3.2/5.7 MB 8.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 3.7/5.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.3/5.7 MB 9.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 4.8/5.7 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.3/5.7 MB 9.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.7/5.7 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------- ----- 450.6/536.2 kB 14.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading torch-2.1.1-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/192.3 MB 11.3 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.1/192.3 MB 11.3 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.6/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 2.2/192.3 MB 11.5 MB/s eta 0:00:17\n",
      "    --------------------------------------- 2.7/192.3 MB 11.5 MB/s eta 0:00:17\n",
      "    --------------------------------------- 3.3/192.3 MB 11.6 MB/s eta 0:00:17\n",
      "    --------------------------------------- 3.8/192.3 MB 11.5 MB/s eta 0:00:17\n",
      "    --------------------------------------- 4.3/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 4.8/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 5.4/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 5.9/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.4/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 7.0/192.3 MB 11.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.5/192.3 MB 11.5 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 8.1/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 8.1/192.3 MB 11.6 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 8.1/192.3 MB 11.6 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 9.2/192.3 MB 11.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 9.7/192.3 MB 11.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 10.3/192.3 MB 11.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 10.8/192.3 MB 11.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 10.9/192.3 MB 11.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 11.8/192.3 MB 10.9 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.2/192.3 MB 10.9 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.6/192.3 MB 10.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 13.0/192.3 MB 10.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 13.4/192.3 MB 10.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 13.9/192.3 MB 10.4 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 14.4/192.3 MB 10.4 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 14.9/192.3 MB 10.4 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 15.3/192.3 MB 10.2 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 15.7/192.3 MB 10.2 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 16.2/192.3 MB 10.1 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 16.7/192.3 MB 10.1 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 17.1/192.3 MB 9.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 17.6/192.3 MB 9.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 18.1/192.3 MB 9.8 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 18.6/192.3 MB 10.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 19.0/192.3 MB 10.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 19.5/192.3 MB 10.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 19.9/192.3 MB 10.1 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 20.3/192.3 MB 9.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 20.6/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 21.0/192.3 MB 9.5 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 21.3/192.3 MB 9.8 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 21.7/192.3 MB 9.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 22.0/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 22.5/192.3 MB 9.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 23.0/192.3 MB 9.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 23.5/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 24.0/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 24.5/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 24.9/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 25.4/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 25.9/192.3 MB 9.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 26.4/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 26.9/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 27.4/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 27.9/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 28.4/192.3 MB 9.6 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 28.9/192.3 MB 9.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 29.4/192.3 MB 9.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 29.9/192.3 MB 9.9 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 30.4/192.3 MB 10.1 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 30.9/192.3 MB 10.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 31.4/192.3 MB 10.4 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 31.9/192.3 MB 10.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 32.4/192.3 MB 10.7 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 32.9/192.3 MB 10.7 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 33.4/192.3 MB 10.7 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 33.8/192.3 MB 10.9 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 34.1/192.3 MB 10.7 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 34.7/192.3 MB 10.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 35.1/192.3 MB 10.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 35.4/192.3 MB 10.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 35.8/192.3 MB 10.2 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 36.2/192.3 MB 10.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 36.6/192.3 MB 9.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 36.9/192.3 MB 9.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 37.3/192.3 MB 9.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 37.7/192.3 MB 9.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 38.1/192.3 MB 9.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 38.5/192.3 MB 9.6 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 38.8/192.3 MB 9.5 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 39.2/192.3 MB 9.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 39.6/192.3 MB 9.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 40.0/192.3 MB 9.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 40.4/192.3 MB 9.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 40.7/192.3 MB 9.0 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 41.2/192.3 MB 9.0 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 41.6/192.3 MB 8.8 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 42.0/192.3 MB 8.8 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 42.4/192.3 MB 8.7 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 42.8/192.3 MB 8.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 43.2/192.3 MB 8.6 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 43.6/192.3 MB 8.5 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 44.0/192.3 MB 8.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 44.4/192.3 MB 8.6 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 44.8/192.3 MB 8.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 45.2/192.3 MB 8.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 45.4/192.3 MB 8.5 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 46.0/192.3 MB 8.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 46.2/192.3 MB 8.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 46.5/192.3 MB 8.3 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 46.8/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 47.1/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 47.5/192.3 MB 8.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 47.7/192.3 MB 8.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 48.0/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 48.3/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 48.7/192.3 MB 7.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 49.0/192.3 MB 7.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 49.3/192.3 MB 7.7 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 49.6/192.3 MB 7.7 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 49.9/192.3 MB 7.7 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 50.2/192.3 MB 7.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 50.5/192.3 MB 7.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 50.8/192.3 MB 7.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 51.1/192.3 MB 7.4 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 51.5/192.3 MB 7.4 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 51.8/192.3 MB 7.4 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 52.1/192.3 MB 7.4 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 52.5/192.3 MB 7.3 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 52.8/192.3 MB 7.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 53.1/192.3 MB 7.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 53.4/192.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 53.6/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 53.9/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 54.3/192.3 MB 6.9 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 54.6/192.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 54.9/192.3 MB 6.8 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 55.3/192.3 MB 6.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 55.6/192.3 MB 6.8 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 55.9/192.3 MB 6.8 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 56.3/192.3 MB 6.8 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 56.6/192.3 MB 6.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 57.0/192.3 MB 6.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 57.3/192.3 MB 6.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 57.6/192.3 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 58.0/192.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 58.3/192.3 MB 6.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 58.7/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 59.0/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 59.3/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 59.7/192.3 MB 7.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 60.0/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 60.4/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 60.7/192.3 MB 7.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 61.1/192.3 MB 7.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 61.3/192.3 MB 7.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 61.6/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 61.9/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 62.2/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 62.4/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 62.8/192.3 MB 7.0 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 63.0/192.3 MB 6.9 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 63.2/192.3 MB 6.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 63.5/192.3 MB 6.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 63.7/192.3 MB 6.7 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 64.0/192.3 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 64.2/192.3 MB 6.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 64.5/192.3 MB 6.7 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 64.7/192.3 MB 6.6 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 65.0/192.3 MB 6.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 65.2/192.3 MB 6.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 65.5/192.3 MB 6.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 65.8/192.3 MB 6.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 66.0/192.3 MB 6.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 66.3/192.3 MB 6.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 66.6/192.3 MB 6.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 66.8/192.3 MB 6.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 67.1/192.3 MB 6.3 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 67.4/192.3 MB 6.2 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 67.6/192.3 MB 6.2 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 67.9/192.3 MB 6.2 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 68.2/192.3 MB 6.2 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 68.4/192.3 MB 6.1 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 68.7/192.3 MB 6.1 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 69.0/192.3 MB 6.1 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 69.2/192.3 MB 6.0 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 69.5/192.3 MB 6.0 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 69.8/192.3 MB 5.9 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 70.1/192.3 MB 5.9 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 70.3/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 70.6/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 70.9/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 71.2/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 71.5/192.3 MB 5.7 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 71.7/192.3 MB 5.7 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 72.0/192.3 MB 5.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 72.3/192.3 MB 5.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 72.6/192.3 MB 5.9 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 72.9/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 73.2/192.3 MB 5.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 73.5/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 73.7/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 74.0/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 74.3/192.3 MB 5.8 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 74.6/192.3 MB 5.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 74.9/192.3 MB 5.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 75.2/192.3 MB 6.0 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 75.5/192.3 MB 6.0 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 75.8/192.3 MB 6.0 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 76.0/192.3 MB 6.0 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 76.3/192.3 MB 6.0 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 76.6/192.3 MB 6.1 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 76.9/192.3 MB 6.1 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 77.2/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 77.5/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 77.8/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 78.1/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 78.4/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 78.7/192.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 79.0/192.3 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 79.3/192.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 79.6/192.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 79.9/192.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 80.2/192.3 MB 6.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 80.4/192.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 80.8/192.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 81.0/192.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 81.3/192.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 81.7/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 82.0/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 82.3/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 82.6/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 82.9/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 83.2/192.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 83.5/192.3 MB 6.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 83.9/192.3 MB 6.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 84.2/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 84.5/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 84.8/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 85.2/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 85.5/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 85.8/192.3 MB 6.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 86.1/192.3 MB 6.6 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 86.4/192.3 MB 6.6 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 86.8/192.3 MB 6.6 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 87.1/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 87.4/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 87.7/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 88.1/192.3 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 88.4/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 88.8/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 89.1/192.3 MB 6.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 89.4/192.3 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 89.8/192.3 MB 6.8 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 90.1/192.3 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 90.4/192.3 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 90.7/192.3 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 91.1/192.3 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 91.5/192.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 91.8/192.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 92.1/192.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 92.5/192.3 MB 7.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 92.8/192.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 93.1/192.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 93.5/192.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 93.8/192.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 94.1/192.3 MB 7.1 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 94.5/192.3 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 94.8/192.3 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 95.2/192.3 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 95.5/192.3 MB 7.2 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 95.9/192.3 MB 7.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 96.2/192.3 MB 7.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 96.6/192.3 MB 7.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 97.0/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 97.3/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 97.7/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 98.0/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 98.4/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 98.7/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 99.1/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 99.5/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 99.8/192.3 MB 7.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 100.2/192.3 MB 7.5 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 100.5/192.3 MB 7.5 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 100.9/192.3 MB 7.5 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 101.2/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 101.6/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 101.9/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 102.3/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 102.7/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 103.0/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 103.4/192.3 MB 7.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 103.8/192.3 MB 7.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 104.2/192.3 MB 7.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 104.5/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 104.9/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 105.3/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 105.6/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 106.0/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 106.3/192.3 MB 7.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 106.7/192.3 MB 7.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 107.0/192.3 MB 7.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 107.2/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 107.5/192.3 MB 7.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 107.8/192.3 MB 7.6 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 108.1/192.3 MB 7.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 108.3/192.3 MB 7.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 108.6/192.3 MB 7.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 108.9/192.3 MB 7.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 109.2/192.3 MB 7.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 109.4/192.3 MB 7.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 109.7/192.3 MB 7.2 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 110.0/192.3 MB 7.2 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 110.3/192.3 MB 7.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 110.6/192.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 110.9/192.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 111.2/192.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 111.5/192.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 111.8/192.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 112.1/192.3 MB 6.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 112.4/192.3 MB 6.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 112.8/192.3 MB 6.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 113.1/192.3 MB 6.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 113.4/192.3 MB 6.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 113.7/192.3 MB 6.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.0/192.3 MB 6.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.3/192.3 MB 6.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.7/192.3 MB 6.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 115.0/192.3 MB 6.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 115.3/192.3 MB 6.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 115.7/192.3 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 116.0/192.3 MB 6.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 116.3/192.3 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 116.6/192.3 MB 6.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 117.0/192.3 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 117.3/192.3 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 117.7/192.3 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 118.0/192.3 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 118.3/192.3 MB 6.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 118.7/192.3 MB 6.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 119.0/192.3 MB 6.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 119.4/192.3 MB 6.9 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 119.7/192.3 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 120.0/192.3 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 120.4/192.3 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 120.8/192.3 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 121.1/192.3 MB 7.1 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 121.4/192.3 MB 7.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 121.8/192.3 MB 7.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 122.2/192.3 MB 7.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 122.6/192.3 MB 7.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 122.9/192.3 MB 7.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 123.3/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 123.6/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 124.0/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 124.4/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 124.7/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 125.0/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 125.2/192.3 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 125.4/192.3 MB 7.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 125.6/192.3 MB 7.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 125.9/192.3 MB 7.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 126.2/192.3 MB 7.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 126.6/192.3 MB 7.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 126.9/192.3 MB 7.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 127.3/192.3 MB 7.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 127.7/192.3 MB 7.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 128.0/192.3 MB 7.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 128.4/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 128.8/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 129.1/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 129.5/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 129.9/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 130.2/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 130.6/192.3 MB 7.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 131.0/192.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 131.3/192.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 131.7/192.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 132.1/192.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 132.5/192.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 132.9/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 133.2/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 133.5/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 133.9/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 134.3/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 134.7/192.3 MB 7.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 135.1/192.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 135.4/192.3 MB 7.7 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 135.8/192.3 MB 8.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 136.2/192.3 MB 8.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 136.6/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 136.9/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 137.3/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 137.7/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 138.1/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 138.5/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 138.8/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 139.2/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 139.6/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 140.0/192.3 MB 8.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 140.4/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 140.7/192.3 MB 8.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 140.9/192.3 MB 8.0 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 141.1/192.3 MB 7.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 141.2/192.3 MB 7.7 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 141.4/192.3 MB 7.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 141.8/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 142.0/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 142.4/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 142.7/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 143.0/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 143.3/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 143.6/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 144.0/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 144.4/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 144.8/192.3 MB 7.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 145.2/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 145.5/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 145.9/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 146.3/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 146.7/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 147.0/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 147.4/192.3 MB 7.3 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 147.7/192.3 MB 7.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.0/192.3 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.1/192.3 MB 7.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.3/192.3 MB 6.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.4/192.3 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.7/192.3 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 148.9/192.3 MB 6.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 149.1/192.3 MB 6.5 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 149.2/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 149.3/192.3 MB 6.3 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 149.6/192.3 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 149.8/192.3 MB 6.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 150.1/192.3 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 150.5/192.3 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 150.8/192.3 MB 6.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 151.2/192.3 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 151.4/192.3 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 151.7/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 152.0/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 152.3/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 152.6/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 152.9/192.3 MB 6.3 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 153.2/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 153.6/192.3 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 153.8/192.3 MB 6.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 154.2/192.3 MB 6.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 154.4/192.3 MB 6.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 154.7/192.3 MB 6.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 155.0/192.3 MB 6.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 155.4/192.3 MB 6.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 155.8/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 156.1/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 156.5/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 156.8/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 157.2/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 157.6/192.3 MB 6.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 158.0/192.3 MB 6.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 158.4/192.3 MB 6.3 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 158.8/192.3 MB 6.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 159.2/192.3 MB 6.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 159.6/192.3 MB 7.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 160.0/192.3 MB 7.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 160.4/192.3 MB 7.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 160.9/192.3 MB 7.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 161.3/192.3 MB 7.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 161.7/192.3 MB 7.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 162.1/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 162.5/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 162.8/192.3 MB 7.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 163.1/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 163.3/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 163.4/192.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 163.6/192.3 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 163.8/192.3 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 164.0/192.3 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 164.4/192.3 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 164.9/192.3 MB 7.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 165.3/192.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 165.7/192.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 166.0/192.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 166.4/192.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 166.8/192.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 167.2/192.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 167.7/192.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 168.1/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 168.5/192.3 MB 7.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 168.9/192.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 169.4/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 169.8/192.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 170.2/192.3 MB 7.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 170.7/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 171.1/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 171.6/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 171.9/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 172.4/192.3 MB 8.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 172.4/192.3 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 172.9/192.3 MB 7.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 173.1/192.3 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 173.2/192.3 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 173.5/192.3 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 173.6/192.3 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 173.8/192.3 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 173.9/192.3 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.1/192.3 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.3/192.3 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.4/192.3 MB 7.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.6/192.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.7/192.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 174.9/192.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.1/192.3 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.2/192.3 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.4/192.3 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.5/192.3 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.6/192.3 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.8/192.3 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 175.9/192.3 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 176.1/192.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 176.3/192.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 176.5/192.3 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 176.7/192.3 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 176.8/192.3 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.0/192.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.2/192.3 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.3/192.3 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.5/192.3 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.7/192.3 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 177.9/192.3 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 178.1/192.3 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 178.2/192.3 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 178.4/192.3 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 178.6/192.3 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 178.8/192.3 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.0/192.3 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.1/192.3 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.3/192.3 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.4/192.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.5/192.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.7/192.3 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 179.8/192.3 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.0/192.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.0/192.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.3/192.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.4/192.3 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.4/192.3 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.7/192.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.7/192.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.8/192.3 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 180.9/192.3 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 181.0/192.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 181.1/192.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 181.2/192.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 181.3/192.3 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 181.4/192.3 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 181.5/192.3 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 181.6/192.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 181.8/192.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 181.9/192.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.0/192.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.1/192.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.2/192.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.3/192.3 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.4/192.3 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.5/192.3 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 182.6/192.3 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 182.8/192.3 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 182.9/192.3 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.0/192.3 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.1/192.3 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.2/192.3 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.3/192.3 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.5/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.6/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.7/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 183.8/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.0/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.1/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.2/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.3/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.5/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.6/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.7/192.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 184.9/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.0/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.1/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.3/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.4/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.5/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.7/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.8/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 185.9/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 186.1/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 186.2/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 186.3/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 186.5/192.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 186.6/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 186.8/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 186.9/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 187.1/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 187.2/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 187.4/192.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  187.5/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  187.7/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  187.8/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.0/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.1/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.3/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.5/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.6/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.8/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  188.9/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  189.1/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  189.2/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  189.4/192.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  189.6/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  189.7/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  189.9/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.1/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.2/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.4/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.6/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.7/192.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.8/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  190.9/192.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.1/192.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.2/192.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.4/192.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.6/192.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.7/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  191.9/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.1/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  192.3/192.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 192.3/192.3 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 143.4/166.4 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 166.4/166.4 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.6 MB 8.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.6 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.6/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.10.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f75d37bf-0e91-404d-a05a-20c86a51155c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.45.0-cp311-cp311-win_amd64.whl.metadata (158 kB)\n",
      "     ---------------------------------------- 0.0/158.1 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/158.1 kB ? eta -:--:--\n",
      "     -------------------- ------------------ 81.9/158.1 kB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 158.1/158.1 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached Pillow-10.1.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.6 MB 5.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.6/7.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/7.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.4/7.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.4/7.6 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.9/7.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.2/7.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.7/7.6 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.0/7.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.5/7.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.0/7.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.4/7.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.8/7.6 MB 9.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.3/7.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.6 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.6/187.6 kB 11.1 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.45.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 9.2 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "Using cached Pillow-10.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.45.0 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.1.0 pyparsing-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e04a79e-673c-4e18-81c2-c399025cf008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB 660.6 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.1/10.6 MB 1.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/10.6 MB 3.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.8/10.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/10.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/10.6 MB 6.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.2/10.6 MB 6.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/10.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.5/10.6 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.9/10.6 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.9/10.6 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.4/10.6 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.4/10.6 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.6/10.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.5/10.6 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.0/10.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.1/10.6 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.6/10.6 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.1.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "97bcfa2a-a2f2-4bea-b50f-84cd6ee75aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     -------------------- ------------------- 30.7/60.4 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 809.0 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.2 MB 2.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/9.2 MB 4.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/9.2 MB 5.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 6.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/9.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.4/9.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.2 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.4/9.2 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.9/9.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.4/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.9/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.9/9.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/44.1 MB 8.7 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.9/44.1 MB 9.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.4/44.1 MB 9.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.9/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.4/44.1 MB 11.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.9/44.1 MB 10.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 3.4/44.1 MB 10.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 3.8/44.1 MB 10.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 4.2/44.1 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.6/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.0/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.6/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.8/44.1 MB 10.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.9/44.1 MB 9.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.1/44.1 MB 10.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.4/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.8/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.2/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.8/44.1 MB 10.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.3/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.8/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.3/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.6/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.9/44.1 MB 9.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.4/44.1 MB 9.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.6/44.1 MB 9.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 12.0/44.1 MB 9.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.5/44.1 MB 9.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.1/44.1 MB 9.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.6/44.1 MB 9.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.1/44.1 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 14.6/44.1 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.2/44.1 MB 10.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.7/44.1 MB 10.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.2/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.8/44.1 MB 10.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.3/44.1 MB 10.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.8/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.4/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.3/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.8/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.4/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.9/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.4/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.9/44.1 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.4/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.9/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.4/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.8/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.3/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.4/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.4/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.4/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 27.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.4/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.5/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.0/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.5/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 30.9/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.0/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.6/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.1/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.6/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.1/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.7/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.2/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.7/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.2/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.8/44.1 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.3/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.7/44.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.0/44.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.7/44.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.1/44.1 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.2/44.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.7/44.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.0/44.1 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.3/44.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/44.1 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.0/44.1 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/44.1 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.8/44.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.1/44.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.4/44.1 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febd003",
   "metadata": {},
   "source": [
    "## 1. Index-based Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "606e6a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': 5, 'dog': 1, '<unk>': 0, 'man': 2, 'bites': 3, 'meat': 6, 'eats': 4}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat\", \"man eats food\"]\n",
    "\n",
    "# Define the max vocabulary size\n",
    "vocab_size = 8\n",
    "\n",
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(data),\n",
    "    max_tokens=vocab_size,\n",
    "    specials=[\"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e006c916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(tokenizer(\"dog bites man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75a5ec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(tokenizer(\"dog and man\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789d8ab",
   "metadata": {},
   "source": [
    "## 2. Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "726d7446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "data = [\"dog bites man\", \"man bites dog\", \"dog eats meat\", \"man eats food\"]\n",
    "\n",
    "# Define the max vocabulary size\n",
    "vocab_size = 8\n",
    "\n",
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(data),\n",
    "    max_tokens=vocab_size,\n",
    "    specials=[\"<pad>\", \"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "vocab.get_stoi()['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49a25f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 3, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.transforms import PadTransform\n",
    "\n",
    "# define padding\n",
    "max_len = 4\n",
    "pad_id = vocab.get_stoi()['<pad>']\n",
    "padder = PadTransform(max_len, pad_id)\n",
    "\n",
    "input = torch.tensor([2, 4, 3])\n",
    "padded_input = padder(input)\n",
    "padded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187af4f-8adc-430c-a5d6-c345668e03c0",
   "metadata": {},
   "source": [
    "## 3. Truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a67207d5-88d9-4ae4-9190-24c7db5736ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 4]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.transforms import Truncate\n",
    "\n",
    "# define padding\n",
    "max_len = 3\n",
    "truncater = Truncate(max_len)\n",
    "\n",
    "input = [2, 2, 4, 3]\n",
    "truncated_input = truncater(input)\n",
    "truncated_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784ccf0-db71-4dda-bd2d-a385d854e88b",
   "metadata": {},
   "source": [
    "## 4. Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1e47eba4-e92d-4482-996c-b984dfe542cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7012,  0.5156, -1.3145],\n",
       "        [ 2.0140,  0.4412, -0.6076],\n",
       "        [-0.7871,  0.4287, -1.1563],\n",
       "        [-0.1437, -2.0789, -2.1529],\n",
       "        [-0.7808, -0.4360, -1.4220],\n",
       "        [ 1.2500, -0.2108,  0.8394],\n",
       "        [-0.7213,  1.2346,  1.1259]], requires_grad=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 7\n",
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "75dcf7bf-315f-46f6-b160-1fcdebb026e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0140,  0.4412, -0.6076],\n",
       "         [-0.7871,  0.4287, -1.1563],\n",
       "         [-0.7808, -0.4360, -1.4220]],\n",
       "\n",
       "        [[-0.7808, -0.4360, -1.4220],\n",
       "         [-0.1437, -2.0789, -2.1529],\n",
       "         [-0.7871,  0.4287, -1.1563]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.LongTensor([[1, 2, 4], [4, 3, 2]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8df187-909d-4810-9b20-0df07db68537",
   "metadata": {},
   "source": [
    "## 5. EmbeddingBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c1b94d51-7abb-4ed8-b862-215f85c677d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1768,  0.4174,  0.5940, -0.6569],\n",
       "        [ 0.3359, -0.1065, -0.5740, -0.0599],\n",
       "        [ 1.0655, -0.2712, -2.0895, -1.0111],\n",
       "        [-0.1228, -1.0042, -0.3422, -0.3102],\n",
       "        [-2.1499, -0.4793, -0.2896,  1.0670],\n",
       "        [-0.5226, -0.6914, -0.2474, -0.1065],\n",
       "        [ 0.8620,  0.7267, -1.8333,  0.1925]], requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 7\n",
    "embedding_dim = 4\n",
    "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='sum')\n",
    "embedding_sum.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e86ea113-1e60-4a94-be24-58ea794720f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7485, -0.8571, -2.9531, -0.0039],\n",
       "        [-2.7953, -2.1749, -0.8792,  0.6503]], grad_fn=<EmbeddingBagBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
    "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
    "embedding_sum(inputs, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3d227d7-18e2-4da7-9c0d-d0586de288e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4686, -0.6659, -0.7198, -0.0650],\n",
       "        [-1.0210, -0.2750,  0.8982,  0.3015],\n",
       "        [-1.5750, -0.3921,  0.2104, -0.1903],\n",
       "        [-0.5328,  0.6035,  0.3171, -1.0613],\n",
       "        [-1.6442, -0.0643, -0.0572, -1.6898],\n",
       "        [-0.7412,  0.0459, -0.4299,  1.6430],\n",
       "        [ 1.0133, -0.4243, -0.2591, -2.1414]], requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 7\n",
    "embedding_dim = 4\n",
    "embedding_sum = nn.EmbeddingBag(vocab_size, embedding_dim, mode='mean')\n",
    "embedding_sum.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ec6fdaa9-e09a-4f03-a0d6-34162b5a9d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4134, -0.2438,  0.3505, -0.5262],\n",
       "        [-0.9728,  0.1950, -0.0567, -0.3694]], grad_fn=<EmbeddingBagBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([1, 2, 4, 5, 4, 3], dtype=torch.long)\n",
    "offsets = torch.tensor([0, 3], dtype=torch.long)\n",
    "embedding_sum(inputs, offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f5615-747d-4f13-928d-f14eae831dd9",
   "metadata": {},
   "source": [
    "# II. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ceb9e7-9a2f-44de-9dd8-8542ff2f6ec7",
   "metadata": {},
   "source": [
    "## 1. Download Dataset from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92631702-d029-48fc-bd21-f1ce0c93c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ntc-scv'...\n",
      "Updating files:  90% (10/11)\n",
      "Updating files: 100% (11/11)\n",
      "Updating files: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/congnghia0609/ntc-scv.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bda68c-d333-45b3-ad35-80b0a354abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf ./ntc-scv/data/data_test.zip -C ./data\n",
    "!tar -xf ./ntc-scv/data/data_train.zip -C ./data\n",
    "#!rd /s /q ntc-scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3633f22-16c8-4733-ac54-505a9dd24f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rd /s /q ntc-scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "126ba463-a527-44d0-8e28-19effd45f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_path(folder_path):\n",
    "    examples = []\n",
    "    for label in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, label)\n",
    "        for file_name in os.listdir(full_path):\n",
    "            file_path = os.path.join(full_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            sentence = \" \".join(lines)\n",
    "            if label == \"neg\":\n",
    "                label = 0\n",
    "            if label == \"pos\":\n",
    "                label = 1\n",
    "            data = {\n",
    "                'sentence': sentence,\n",
    "                'label': label\n",
    "            }\n",
    "            examples.append(data)\n",
    "    return pd.DataFrame(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "36c3910a-b282-40f5-94ba-9903e314207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = {\n",
    "    'train': './data/data_train/train',\n",
    "    'valid': './data/data_train/test',\n",
    "    'test': './data/data_test/test'\n",
    "}\n",
    "\n",
    "train_df = load_data_from_path(folder_paths['train'])\n",
    "valid_df = load_data_from_path(folder_paths['valid'])\n",
    "test_df = load_data_from_path(folder_paths['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4079a623-d621-42e0-80e9-6c19d633a62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c mi Bingsu thp_cm 45k m mnh f i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 6 no ta cng quy   \\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mnh i vi nhm , tng_cng 4 ngi n ch c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhn_vin phc_v khng my tn_tnh , _n r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vo y th ht bn , nhng mnh vn ngi i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  Mua c mi Bingsu thp_cm 45k m mnh f i h...      0\n",
       "1  Th 6 no ta cng quy   \\n Vuvuzela beer c...      0\n",
       "2  Mnh i vi nhm , tng_cng 4 ngi n ch c...      0\n",
       "3  nhn_vin phc_v khng my tn_tnh , _n r...      0\n",
       "4  Vo y th ht bn , nhng mnh vn ngi i ...      0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b77f7-4884-4707-8a34-662682dc7e78",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e58743-a39c-4a68-ac51-307895ffc389",
   "metadata": {},
   "source": [
    "### 2.1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc354d2-5bef-4be6-8cca-08bf8b6f4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\basicnlpaio\\lib\\site-packages (from langid) (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96e0699f-b42d-401a-a974-18ad40d6b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langid.langid import LanguageIdentifier, model\n",
    "\n",
    "def identify_vn(df):\n",
    "    identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "    not_vi_idx = set()\n",
    "    THRESHOLD = 0.9\n",
    "    for idx, row in df.iterrows():\n",
    "        score = identifier.classify(row[\"sentence\"])\n",
    "        if score[0] != \"vi\" or (score[0] == \"vi\" and score[1] <= THRESHOLD):\n",
    "            not_vi_idx.add(idx)\n",
    "    vi_df = df[~df.index.isin(not_vi_idx)]\n",
    "    not_vi_df = df[df.index.isin(not_vi_idx)]\n",
    "    return vi_df, not_vi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cdc8bd41-3353-464f-a7cd-4909f23092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_vi, train_df_other = identify_vn(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "17519ac6-98fe-4876-8f6a-1aca7c0a9ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c mi Bingsu thp_cm 45k m mnh f i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 6 no ta cng quy   \\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mnh i vi nhm , tng_cng 4 ngi n ch c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhn_vin phc_v khng my tn_tnh , _n r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vo y th ht bn , nhng mnh vn ngi i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>sushi bnh_dn m cht_lng khng bnh_dn ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Tri_i t b n ln cha th mn kem no bn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Nge mn cng ns ngon nn hni n coi th_no .\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Ks p . Thog mt . Li gn vs ph c na nn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29736 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0      Mua c mi Bingsu thp_cm 45k m mnh f i h...      0\n",
       "1      Th 6 no ta cng quy   \\n Vuvuzela beer c...      0\n",
       "2      Mnh i vi nhm , tng_cng 4 ngi n ch c...      0\n",
       "3      nhn_vin phc_v khng my tn_tnh , _n r...      0\n",
       "4      Vo y th ht bn , nhng mnh vn ngi i ...      0\n",
       "...                                                  ...    ...\n",
       "29995  2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...      1\n",
       "29996  sushi bnh_dn m cht_lng khng bnh_dn ch...      1\n",
       "29997  Tri_i t b n ln cha th mn kem no bn...      1\n",
       "29998  Nge mn cng ns ngon nn hni n coi th_no .\\...      1\n",
       "29999  Ks p . Thog mt . Li gn vs ph c na nn...      1\n",
       "\n",
       "[29736 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97c6285e-499a-445f-8852-008c4ef0beac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Minh da den them 1 lan vao buoi trua ma van do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>The drink taste not good as Shanghai . The tas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>I work in District 1 not far from Taco_King . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Service is worst . . waiter and waitress messi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Day la lan dau cung nhu lan cuoi minh ghe quan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29571</th>\n",
       "      <td>We had high expectations of this place and my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29687</th>\n",
       "      <td>My name is Luan ,  A_Local_Travel_Consultant ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29757</th>\n",
       "      <td>Art of lanterns , super nice and acceptable pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29853</th>\n",
       "      <td>The 200k buffet is really worth it ! Good meat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29940</th>\n",
       "      <td>Brilliant juices ! ! They have some mixes that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "446    Minh da den them 1 lan vao buoi trua ma van do...      0\n",
       "523    The drink taste not good as Shanghai . The tas...      0\n",
       "582    I work in District 1 not far from Taco_King . ...      0\n",
       "802    Service is worst . . waiter and waitress messi...      0\n",
       "809    Day la lan dau cung nhu lan cuoi minh ghe quan...      0\n",
       "...                                                  ...    ...\n",
       "29571  We had high expectations of this place and my ...      1\n",
       "29687  My name is Luan ,  A_Local_Travel_Consultant ...      1\n",
       "29757  Art of lanterns , super nice and acceptable pr...      1\n",
       "29853  The 200k buffet is really worth it ! Good meat...      1\n",
       "29940  Brilliant juices ! ! They have some mixes that...      1\n",
       "\n",
       "[264 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42125f-4783-4563-aa17-b07b478f233f",
   "metadata": {},
   "source": [
    "### 2.2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6392ba85-4dcf-4a93-8ac2-06cd021dca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    url_pattern = re.compile(r'https?://\\s+\\wwww\\.\\s+')\n",
    "    text = url_pattern.sub(r\" \", text)\n",
    "\n",
    "    html_pattern = re.compile(r'<[^<>]+>')\n",
    "    text = html_pattern.sub(\" \", text)\n",
    "\n",
    "    replace_chars = list(string.punctuation + string.digits)\n",
    "    for char in replace_chars:\n",
    "        text = text.replace(char, \" \")\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r\" \", text)\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e28b17dd-939b-48da-9ad7-4a1f98bafd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mot', 'hai', 'ba', 'bon']\n",
      "Mot hai ba bon\n"
     ]
    }
   ],
   "source": [
    "text = 'Mot    hai     ba   bon'\n",
    "temp = text.split()\n",
    "print(temp)\n",
    "text = ' '.join(temp)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "abe568f8-3bed-4e95-852b-87241f4d5e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mua c mi Bingsu thp_cm 45k m mnh f i hn 20 \\' . Hi li th nv tl c r nhg bo ch thm 15 \\' na \" ti e lm lin \" .\\n Mnh k bit c ngon k nhg cng mun n th . Thit_ngh nv qun nn xem_li cch pv v nc vs khch .\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_vi['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e477baef-e972-474b-a4dd-40fac08819a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mua c mi bingsu thp cm k m mnh f i hn hi li th nv tl c r nhg bo ch thm na ti e lm lin mnh k bit c ngon k nhg cng mun n th thit ngh nv qun nn xem li cch pv v nc vs khch'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(train_df_vi['sentence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08039992-fd7c-46a1-95c8-514f866d40fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14156\\1058621333.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "train_df_vi['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in train_df_vi.iterrows()]\n",
    "valid_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in valid_df.iterrows()]\n",
    "test_df['preprocess_sentence'] = [preprocess_text(row['sentence']) for index, row in test_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cf96b696-28a7-44f4-950b-15cc035c9c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c mi Bingsu thp_cm 45k m mnh f i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 6 no ta cng quy   \\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mnh i vi nhm , tng_cng 4 ngi n ch c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhn_vin phc_v khng my tn_tnh , _n r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vo y th ht bn , nhng mnh vn ngi i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>sushi bnh_dn m cht_lng khng bnh_dn ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Tri_i t b n ln cha th mn kem no bn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Nge mn cng ns ngon nn hni n coi th_no .\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Ks p . Thog mt . Li gn vs ph c na nn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0      Mua c mi Bingsu thp_cm 45k m mnh f i h...      0\n",
       "1      Th 6 no ta cng quy   \\n Vuvuzela beer c...      0\n",
       "2      Mnh i vi nhm , tng_cng 4 ngi n ch c...      0\n",
       "3      nhn_vin phc_v khng my tn_tnh , _n r...      0\n",
       "4      Vo y th ht bn , nhng mnh vn ngi i ...      0\n",
       "...                                                  ...    ...\n",
       "29995  2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...      1\n",
       "29996  sushi bnh_dn m cht_lng khng bnh_dn ch...      1\n",
       "29997  Tri_i t b n ln cha th mn kem no bn...      1\n",
       "29998  Nge mn cng ns ngon nn hni n coi th_no .\\...      1\n",
       "29999  Ks p . Thog mt . Li gn vs ph c na nn...      1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a64ccf00-c545-4d33-b994-ec952c0c3de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ln u_tin n chc cng l ln cui n_ y...</td>\n",
       "      <td>0</td>\n",
       "      <td>ln u tin n chc cng l ln cui n  y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Khi mnh vo th bn cha dn , d kinh . Ci ...</td>\n",
       "      <td>0</td>\n",
       "      <td>khi mnh vo th bn cha dn d kinh ci bp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haiz ! Khng bit ng hng_v ca bnh th_n...</td>\n",
       "      <td>0</td>\n",
       "      <td>haiz khng bit ng hng v ca bnh th no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mnh gh qun ny v thy c cm theo kiu Vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>mnh gh qun ny v thy c cm theo kiu vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qun xn  Quan_Hoa - Cu_Giy , bin_hiu mu...</td>\n",
       "      <td>0</td>\n",
       "      <td>qun xn  quan hoa cu giy bin hiu mu xan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Qun khng_gian nh nhng kh lch_s , sch_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>qun khng gian nh nhng kh lch s sch s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>i n ln 2 : ) ) ) ln ny rt kinh_nghim ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>i n ln ln ny rt kinh nghim kiu  n t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Mnh n 2 mn , m qun tn mt ri , ton t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mnh n mn m qun tn mt ri ton t c hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Trong nh l\\n  1 phn m udon xo\\n  1 phn...</td>\n",
       "      <td>1</td>\n",
       "      <td>trong nh l  phn m udon xo  phn cun ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>a_im : d tm , mu thn quo vo ng b...</td>\n",
       "      <td>1</td>\n",
       "      <td>a im d tm mu thn quo vo ng b h ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0     Ln u_tin n chc cng l ln cui n_ y...      0   \n",
       "1     Khi mnh vo th bn cha dn , d kinh . Ci ...      0   \n",
       "2     Haiz ! Khng bit ng hng_v ca bnh th_n...      0   \n",
       "3     Mnh gh qun ny v thy c cm theo kiu Vi...      0   \n",
       "4     Qun xn  Quan_Hoa - Cu_Giy , bin_hiu mu...      0   \n",
       "...                                                 ...    ...   \n",
       "9995  Qun khng_gian nh nhng kh lch_s , sch_s...      1   \n",
       "9996  i n ln 2 : ) ) ) ln ny rt kinh_nghim ki...      1   \n",
       "9997  Mnh n 2 mn , m qun tn mt ri , ton t ...      1   \n",
       "9998  Trong nh l\\n  1 phn m udon xo\\n  1 phn...      1   \n",
       "9999  a_im : d tm , mu thn quo vo ng b...      1   \n",
       "\n",
       "                                    preprocess_sentence  \n",
       "0     ln u tin n chc cng l ln cui n  y...  \n",
       "1     khi mnh vo th bn cha dn d kinh ci bp ...  \n",
       "2     haiz khng bit ng hng v ca bnh th no...  \n",
       "3     mnh gh qun ny v thy c cm theo kiu vi...  \n",
       "4     qun xn  quan hoa cu giy bin hiu mu xan...  \n",
       "...                                                 ...  \n",
       "9995  qun khng gian nh nhng kh lch s sch s ...  \n",
       "9996  i n ln ln ny rt kinh nghim kiu  n t...  \n",
       "9997  mnh n mn m qun tn mt ri ton t c hi...  \n",
       "9998  trong nh l  phn m udon xo  phn cun ki...  \n",
       "9999  a im d tm mu thn quo vo ng b h ...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f37648a8-20bd-420a-bde3-d121d0df8993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qun ny kh l ni_ting nay mi c dp gh t...</td>\n",
       "      <td>0</td>\n",
       "      <td>qun ny kh l ni ting nay mi c dp gh t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y l ln u_tin mnh n_ y , v c_l c...</td>\n",
       "      <td>0</td>\n",
       "      <td>y l ln u tin mnh n  y v c l cn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tha  i   phu  c vu  nhn_vin khng t ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tha  i   phu  c vu  nhn vin khng t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_n bnh_thng . Cn chm_cht khng_gian h...</td>\n",
       "      <td>0</td>\n",
       "      <td> n bnh thng cn chm cht khng gian hn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phc_v lu , gi th n thi nhng cht_lng...</td>\n",
       "      <td>0</td>\n",
       "      <td>phc v lu gi th n thi nhng cht lng b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Gia re , mon an ngon , view dep va nhan vien n...</td>\n",
       "      <td>1</td>\n",
       "      <td>gia re mon an ngon view dep va nhan vien nhiet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Qun nm trn ng Thch_Th_Thanh , d tm ....</td>\n",
       "      <td>1</td>\n",
       "      <td>qun nm trn ng thch th thanh d tm kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Mnh  n n_ qun ny vi ln . _n ngon...</td>\n",
       "      <td>1</td>\n",
       "      <td>mnh  n n  qun ny vi ln  n ngon g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Nh_hng trang_tr c_o .\\n Mn n mi_l n...</td>\n",
       "      <td>1</td>\n",
       "      <td>nh hng trang tr c o mn n mi l nhiu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Qun c  ung ht_d nht khu_vc TC . Siu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>qun c  ung ht d nht khu vc tc siu r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0     Qun ny kh l ni_ting nay mi c dp gh t...      0   \n",
       "1     y l ln u_tin mnh n_ y , v c_l c...      0   \n",
       "2     tha  i   phu  c vu  nhn_vin khng t ...      0   \n",
       "3     _n bnh_thng . Cn chm_cht khng_gian h...      0   \n",
       "4     Phc_v lu , gi th n thi nhng cht_lng...      0   \n",
       "...                                                 ...    ...   \n",
       "9995  Gia re , mon an ngon , view dep va nhan vien n...      1   \n",
       "9996  Qun nm trn ng Thch_Th_Thanh , d tm ....      1   \n",
       "9997  Mnh  n n_ qun ny vi ln . _n ngon...      1   \n",
       "9998  Nh_hng trang_tr c_o .\\n Mn n mi_l n...      1   \n",
       "9999  Qun c  ung ht_d nht khu_vc TC . Siu ...      1   \n",
       "\n",
       "                                    preprocess_sentence  \n",
       "0     qun ny kh l ni ting nay mi c dp gh t...  \n",
       "1     y l ln u tin mnh n  y v c l cn...  \n",
       "2     tha  i   phu  c vu  nhn vin khng t ...  \n",
       "3      n bnh thng cn chm cht khng gian hn...  \n",
       "4     phc v lu gi th n thi nhng cht lng b...  \n",
       "...                                                 ...  \n",
       "9995  gia re mon an ngon view dep va nhan vien nhiet...  \n",
       "9996  qun nm trn ng thch th thanh d tm kh...  \n",
       "9997  mnh  n n  qun ny vi ln  n ngon g...  \n",
       "9998  nh hng trang tr c o mn n mi l nhiu...  \n",
       "9999  qun c  ung ht d nht khu vc tc siu r...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1685e12-74d0-4c65-8e74-5b3bc90530fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocess_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mua c mi Bingsu thp_cm 45k m mnh f i h...</td>\n",
       "      <td>0</td>\n",
       "      <td>mua c mi bingsu thp cm k m mnh f i hn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 6 no ta cng quy   \\n Vuvuzela beer c...</td>\n",
       "      <td>0</td>\n",
       "      <td>th no ta cng quy vuvuzela beer club chung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mnh i vi nhm , tng_cng 4 ngi n ch c...</td>\n",
       "      <td>0</td>\n",
       "      <td>mnh i vi nhm tng cng ngi n ch c kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhn_vin phc_v khng my tn_tnh , _n r...</td>\n",
       "      <td>0</td>\n",
       "      <td>nhn vin phc v khng my tn tnh  n ra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vo y th ht bn , nhng mnh vn ngi i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>vo y th ht bn nhng mnh vn ngi i b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>mnh i vi nhm bn tng cng l ng thit hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>sushi bnh_dn m cht_lng khng bnh_dn ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>sushi bnh dn m cht lng khng bnh dn ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Tri_i t b n ln cha th mn kem no bn...</td>\n",
       "      <td>1</td>\n",
       "      <td>tri i t b n ln cha th mn kem no bn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Nge mn cng ns ngon nn hni n coi th_no .\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>nge mn cng ns ngon nn hni n coi th no qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Ks p . Thog mt . Li gn vs ph c na nn...</td>\n",
       "      <td>1</td>\n",
       "      <td>ks p thog mt li gn vs ph c na nn rt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29736 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label  \\\n",
       "0      Mua c mi Bingsu thp_cm 45k m mnh f i h...      0   \n",
       "1      Th 6 no ta cng quy   \\n Vuvuzela beer c...      0   \n",
       "2      Mnh i vi nhm , tng_cng 4 ngi n ch c...      0   \n",
       "3      nhn_vin phc_v khng my tn_tnh , _n r...      0   \n",
       "4      Vo y th ht bn , nhng mnh vn ngi i ...      0   \n",
       "...                                                  ...    ...   \n",
       "29995  2-9 mnh i vi nhm bn tng_cng l 8ng.Thi...      1   \n",
       "29996  sushi bnh_dn m cht_lng khng bnh_dn ch...      1   \n",
       "29997  Tri_i t b n ln cha th mn kem no bn...      1   \n",
       "29998  Nge mn cng ns ngon nn hni n coi th_no .\\...      1   \n",
       "29999  Ks p . Thog mt . Li gn vs ph c na nn...      1   \n",
       "\n",
       "                                     preprocess_sentence  \n",
       "0      mua c mi bingsu thp cm k m mnh f i hn...  \n",
       "1      th no ta cng quy vuvuzela beer club chung ...  \n",
       "2      mnh i vi nhm tng cng ngi n ch c kh...  \n",
       "3      nhn vin phc v khng my tn tnh  n ra ...  \n",
       "4      vo y th ht bn nhng mnh vn ngi i b...  \n",
       "...                                                  ...  \n",
       "29995  mnh i vi nhm bn tng cng l ng thit hi...  \n",
       "29996  sushi bnh dn m cht lng khng bnh dn ch...  \n",
       "29997  tri i t b n ln cha th mn kem no bn...  \n",
       "29998  nge mn cng ns ngon nn hni n coi th no qu...  \n",
       "29999  ks p thog mt li gn vs ph c na nn rt...  \n",
       "\n",
       "[29736 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24580580-f0a9-4510-9f84-31de0f7597f2",
   "metadata": {},
   "source": [
    "### 2.3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "86d0d5bd-688e-45bc-b524-d86b2608af3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(sentence.split()) for sentence in train_df_vi['preprocess_sentence']], bins=128, range=(0, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a99433a9-9b5d-4053-ba3b-0a2bacb080d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17244, 2856797)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count: words and vocabulary\n",
    "from collections import Counter\n",
    "\n",
    "words = []\n",
    "[[words.append(word) for word in sentence.split()] for sentence in train_df_vi['preprocess_sentence']]\n",
    "vocabulary = Counter(words)\n",
    "len(vocabulary), len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b87fc-942d-49ac-9dce-ac6673eeb706",
   "metadata": {},
   "source": [
    "## 3. Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a8d01878-2d2d-42d3-aeea-9e2ffb09aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(sentences, tokenizer):\n",
    "    for sentence in sentences:\n",
    "        yield tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "afae7b59-c4f5-4bc5-9a5a-a10c1a5642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-based tokenizer\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c375e358-5f45-4d17-adf3-9aa41e082171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mua', 'c', 'mi', 'bingsu', 'thp']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_df_vi['preprocess_sentence'][0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "423e9ce4-0240-477e-bb83-6ca4107d1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab_size = 10000\n",
    "vocabulary = build_vocab_from_iterator(\n",
    "    yield_tokens(train_df_vi['preprocess_sentence'], tokenizer),\n",
    "    max_tokens=vocab_size,\n",
    "    specials=[\"<unk>\"]\n",
    ")\n",
    "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5de268ad-51ea-4cb5-90d3-e851f37a8e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5c3ed501-45ad-46f4-a9dd-bfe37f30d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60]\n"
     ]
    }
   ],
   "source": [
    "# encode text\n",
    "\n",
    "print(vocabulary(tokenizer(train_df_vi['preprocess_sentence'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d85ffddf-600b-4c03-802a-d3a3ca0c033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['preprocess_sentence']\n",
    "        encoded_sentence = vocabulary(tokenizer(sentence))\n",
    "        label = row['label']\n",
    "        yield encoded_sentence, label\n",
    "\n",
    "train_dataset = prepare_dataset(train_df_vi)\n",
    "train_dataset = to_map_style_dataset(train_dataset)\n",
    "\n",
    "valid_dataset = prepare_dataset(valid_df)\n",
    "valid_dataset = to_map_style_dataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dc5bd5b8-b2b4-4784-9325-90d78b10c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([140, 3, 205, 890, 913, 856, 13, 15, 2, 2556, 241, 76, 186, 20, 7, 369, 2495, 3, 565, 1280, 213, 282, 96, 56, 419, 606, 2777, 659, 2, 13, 120, 3, 10, 13, 1280, 9, 175, 1, 98, 648, 331, 369, 6, 17, 287, 20, 189, 1375, 8, 689, 277, 60], 0)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "016839fd-8ad5-42e2-a4df-58d7061d80f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29736"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f277fb-ab5b-4bfc-94ce-e942cc02b923",
   "metadata": {},
   "source": [
    "## 4. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dcb85a55-464f-4f50-806c-41fdd061fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    encoded_sentences, labels, offsets = [], [], [0]\n",
    "    for encoded_sentence, label in batch:\n",
    "        labels.append(label)\n",
    "        encoded_sentence = torch.tensor(encoded_sentence, dtype=torch.int64)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "        offsets.append(encoded_sentence.size(0))\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    encoded_sentences = torch.cat(encoded_sentences)\n",
    "    return encoded_sentences.to(device), offsets.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "22c8ac75-bd3d-4e61-9547-cb8e0e8a85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e473614e-4f70-4920-b8ed-1bb9d31c4efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([116,  57, 182,  ..., 844, 128,  20]),\n",
       " tensor([    0,    16,    65,   108,   180,   324,   400,   507,   542,   673,\n",
       "           791,   870,   893,   928,  1010,  1081,  1181,  1246,  1313,  1338,\n",
       "          1443,  1469,  1545,  1648,  1681,  1747,  1976,  2013,  2097,  2128,\n",
       "          2202,  2241,  2257,  2357,  2460,  2544,  2596,  2664,  2784,  2799,\n",
       "          2889,  2924,  2961,  3065,  3126,  3235,  3339,  3651,  3791,  3813,\n",
       "          3944,  4012,  4241,  4336,  4361,  4497,  4526,  4646,  4872,  4923,\n",
       "          4944,  4982,  5067,  5174,  5251,  5389,  5508,  5599,  5726,  5746,\n",
       "          5785,  5885,  5927,  5966,  6226,  6272,  6309,  6546,  6759,  6796,\n",
       "          6858,  7290,  7372,  7427,  7519,  7533,  7628,  7653,  7726,  7760,\n",
       "          7820,  7838,  7916,  7995,  8185,  8254,  8445,  8494,  8614,  8665,\n",
       "          8756,  8898,  8961,  8991,  9052,  9236,  9312,  9466,  9495,  9581,\n",
       "          9626,  9666,  9947, 10096, 10130, 10224, 10367, 10566, 10594, 10623,\n",
       "         10806, 10842, 10903, 10933, 10997, 11045, 11060, 11081]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "         0, 1, 1, 0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b1f45b1c-2612-4c2d-b402-da8f44b6d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences, offsets, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a948ffc1-520f-4973-a152-99b6968ef852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13259])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11956c-8318-40f9-98b2-9c08d23006de",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49462a8a-3a48-4179-ab44-8e9c454838a2",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "50a4e014-6af4-43cf-8f7d-fb89d9bc86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, seq_len):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.ft = nn.Flatten()\n",
    "        self.fc = nn.Linear(seq_len*embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        ouput = self.ft(embedded)\n",
    "        return self.fc(ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bc5d0671-46e9-4bef-bc2d-91ec93e15813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 10\n",
    "input = torch.ones([batch_size, seq_len], dtype=torch.int32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b842bfe6-8adf-46ec-bbe7-4a581c40d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "vocab_size = 5000\n",
    "embed_dim = 100\n",
    "model = TextClassificationModel(vocab_size, embed_dim, num_class, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dd414795-2c4e-4b6e-84b4-2ebd64fdb3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): Embedding(5000, 100)\n",
       "  (ft): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "55637cdc-8517-47b7-9d78-0ea8bf34e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4081, -0.4070],\n",
       "        [ 1.4081, -0.4070],\n",
       "        [ 1.4081, -0.4070],\n",
       "        [ 1.4081, -0.4070],\n",
       "        [ 1.4081, -0.4070]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(input)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4a6a5-4799-454f-a9de-847b271f4a4d",
   "metadata": {},
   "source": [
    "### EmbeddingBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "36d757f3-c7ee-453a-9789-0a1307849fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedded = self.embedding(inputs, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fadb70b8-7981-4f17-a277-6c54ed6c073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(set(train_df_vi['label']))\n",
    "vocab_size = len(vocabulary)\n",
    "embed_dim = 100\n",
    "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5ad5f590-bcfc-4b16-a25d-e042e7338fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): EmbeddingBag(10000, 100, mode='mean')\n",
       "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e7686831-e3a6-42bf-a911-55b59fc04784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9113e-02, -2.4893e-02],\n",
       "        [ 1.1344e-01,  2.1984e-01],\n",
       "        [ 2.1832e-01,  1.0814e-02],\n",
       "        [ 1.8739e-01, -5.3573e-02],\n",
       "        [-2.9708e-02,  1.4616e-01],\n",
       "        [ 5.8519e-02, -5.4750e-02],\n",
       "        [ 1.4334e-01,  8.3761e-02],\n",
       "        [ 1.7434e-01,  1.8472e-01],\n",
       "        [ 1.6583e-01, -5.7495e-03],\n",
       "        [-6.4203e-03, -1.4006e-01],\n",
       "        [ 1.9806e-01,  5.1644e-02],\n",
       "        [ 1.1344e-01, -8.5453e-02],\n",
       "        [ 1.1119e-01, -1.8860e-01],\n",
       "        [-7.2048e-03, -1.0170e-01],\n",
       "        [ 1.3507e-02, -3.7617e-02],\n",
       "        [ 8.6525e-02, -8.6310e-02],\n",
       "        [ 1.2098e-01, -5.8796e-02],\n",
       "        [ 5.9183e-02, -4.8672e-02],\n",
       "        [ 6.1043e-02, -8.0692e-02],\n",
       "        [-2.3744e-02,  2.8046e-01],\n",
       "        [ 6.8874e-02, -4.2777e-03],\n",
       "        [ 3.7901e-01,  2.8211e-01],\n",
       "        [ 6.0494e-02, -5.8338e-02],\n",
       "        [-8.1229e-02, -5.7431e-03],\n",
       "        [ 2.2162e-01,  2.0491e-01],\n",
       "        [ 1.2702e-01,  3.2595e-02],\n",
       "        [ 2.0836e-01, -1.4376e-01],\n",
       "        [ 8.8865e-02, -3.4439e-02],\n",
       "        [ 1.2267e-01,  1.7494e-01],\n",
       "        [ 5.9627e-02,  7.8029e-03],\n",
       "        [ 2.5534e-02, -1.5773e-02],\n",
       "        [ 1.0335e-01,  2.9306e-02],\n",
       "        [ 1.5313e-01,  1.0575e-01],\n",
       "        [ 2.4100e-02, -8.2771e-02],\n",
       "        [ 2.3043e-01,  1.3373e-01],\n",
       "        [ 1.6687e-01, -2.4178e-03],\n",
       "        [ 1.9217e-01,  2.4852e-02],\n",
       "        [ 1.5535e-01, -4.8654e-02],\n",
       "        [-6.1542e-03,  1.3569e-01],\n",
       "        [ 2.3755e-02, -2.8789e-03],\n",
       "        [-6.4347e-02, -4.6259e-02],\n",
       "        [ 2.0590e-01, -1.1293e-01],\n",
       "        [ 1.9210e-01, -1.6459e-02],\n",
       "        [ 1.3239e-01,  9.1501e-02],\n",
       "        [ 1.4645e-01,  7.3742e-02],\n",
       "        [-4.2699e-03, -1.6613e-01],\n",
       "        [ 5.8597e-02,  8.7042e-02],\n",
       "        [ 1.6059e-01, -1.2067e-02],\n",
       "        [-7.7212e-02,  6.0986e-02],\n",
       "        [ 1.4647e-01,  1.4603e-01],\n",
       "        [ 3.6560e-02, -3.1582e-02],\n",
       "        [ 1.6903e-01,  1.0185e-01],\n",
       "        [ 3.8381e-02,  5.2980e-02],\n",
       "        [-7.7983e-02, -9.6333e-02],\n",
       "        [ 5.7481e-02, -2.0608e-01],\n",
       "        [ 1.5378e-01, -3.0350e-02],\n",
       "        [ 3.1855e-02,  2.1164e-01],\n",
       "        [ 6.0600e-02,  1.6818e-01],\n",
       "        [ 2.2116e-01, -1.7628e-01],\n",
       "        [ 1.5803e-01, -1.6068e-01],\n",
       "        [-2.2142e-02,  4.8013e-02],\n",
       "        [ 7.8063e-02, -1.6037e-01],\n",
       "        [ 1.8951e-01, -1.2228e-01],\n",
       "        [ 4.7043e-02,  1.3082e-03],\n",
       "        [-8.7992e-03, -1.0624e-01],\n",
       "        [ 4.7367e-02, -4.7376e-02],\n",
       "        [ 8.1530e-02,  5.5370e-02],\n",
       "        [ 2.7525e-02,  5.7721e-02],\n",
       "        [ 3.9167e-02, -3.6849e-02],\n",
       "        [ 8.7639e-02,  2.7295e-03],\n",
       "        [ 4.8831e-01,  4.7116e-02],\n",
       "        [-3.8957e-01, -2.6610e-01],\n",
       "        [-1.3457e-01,  1.3708e-01],\n",
       "        [ 5.8553e-02, -6.3322e-02],\n",
       "        [ 1.7740e-01,  4.6659e-01],\n",
       "        [ 2.5815e-01, -3.1420e-02],\n",
       "        [-1.2880e-01, -4.3851e-03],\n",
       "        [ 7.3090e-04,  9.3463e-02],\n",
       "        [ 9.6093e-02,  5.3669e-02],\n",
       "        [-1.5217e-01, -2.7089e-02],\n",
       "        [-1.1032e-01, -1.4913e-02],\n",
       "        [-9.2257e-02, -1.6205e-01],\n",
       "        [ 2.3725e-01,  5.4991e-02],\n",
       "        [ 1.1642e-01, -4.0909e-02],\n",
       "        [ 8.2543e-02, -1.2392e-01],\n",
       "        [ 1.9851e-01,  6.1526e-02],\n",
       "        [ 1.0701e-01,  1.0617e-01],\n",
       "        [ 1.5505e-01,  5.2949e-02],\n",
       "        [ 4.1173e-02, -1.6283e-01],\n",
       "        [-2.3147e-01,  4.8983e-03],\n",
       "        [ 1.2150e-02,  1.6380e-02],\n",
       "        [ 1.1218e-01, -1.7455e-01],\n",
       "        [ 1.9140e-01,  8.1884e-02],\n",
       "        [ 7.8561e-02, -1.3922e-01],\n",
       "        [ 1.5076e-01,  1.8430e-01],\n",
       "        [-2.0881e-01,  1.5924e-02],\n",
       "        [ 1.7138e-01, -3.1844e-03],\n",
       "        [ 9.9026e-02,  8.8077e-03],\n",
       "        [ 2.2393e-01,  1.0255e-02],\n",
       "        [ 4.7038e-02, -1.4224e-02],\n",
       "        [ 1.0279e-01,  9.8205e-02],\n",
       "        [ 9.5344e-02, -8.1716e-02],\n",
       "        [ 1.3650e-01,  5.1087e-02],\n",
       "        [ 6.9888e-02,  1.3578e-01],\n",
       "        [ 1.4076e-01, -7.6680e-02],\n",
       "        [ 5.5325e-02,  9.6586e-02],\n",
       "        [ 2.5883e-01, -1.3932e-01],\n",
       "        [ 1.1787e-01, -7.7635e-02],\n",
       "        [-2.3804e-02, -3.8673e-02],\n",
       "        [ 2.8615e-04, -5.7393e-02],\n",
       "        [ 2.0680e-01,  5.7064e-02],\n",
       "        [-4.6916e-03, -8.2189e-02],\n",
       "        [ 2.7241e-02,  1.2250e-01],\n",
       "        [-6.9077e-02, -1.6009e-01],\n",
       "        [ 1.6258e-01,  7.1126e-02],\n",
       "        [ 1.4619e-01, -1.0622e-03],\n",
       "        [-1.3456e-01,  1.7582e-01],\n",
       "        [ 2.5817e-01, -1.4247e-01],\n",
       "        [ 1.5039e-01,  2.8514e-02],\n",
       "        [ 3.0134e-03, -6.8832e-02],\n",
       "        [-1.9406e-02, -1.4539e-01],\n",
       "        [ 2.6441e-01,  1.1412e-01],\n",
       "        [-1.2247e-01,  1.4764e-01],\n",
       "        [ 9.7941e-02, -1.4063e-01],\n",
       "        [ 1.4561e-02, -9.0519e-02],\n",
       "        [ 4.1727e-02, -5.1751e-02],\n",
       "        [ 1.1037e-01,  1.1122e-01],\n",
       "        [-1.5457e-01, -3.7966e-02]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(encoded_sentences, offsets)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "13482124-9346-41a1-86b7-68ce9c9b205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5d1236dc-5fbd-42a7-8140-50dfa3c065a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d029b4e9-e3d5-4b7c-ac69-868057a95120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6803, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6381e9-0192-402c-b25b-d806dab48381",
   "metadata": {},
   "source": [
    "## 5. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ee2d7c22-bc33-408b-b318-3c5db231318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, optimizer, criterion, train_dataloader, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, offsets, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs, offsets)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "169bd251-fdd2-4814-8ac1-8c180df2648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |    50/  233 batches | accuracy    0.534\n",
      "| epoch   0 |   100/  233 batches | accuracy    0.539\n",
      "| epoch   0 |   150/  233 batches | accuracy    0.539\n",
      "| epoch   0 |   200/  233 batches | accuracy    0.544\n"
     ]
    }
   ],
   "source": [
    "epoch_acc, epoch_loss = train(model, optimizer, criterion, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ea90e1a3-b91c-42c2-b6b5-8a57a41f1260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5486526946107785, 0.6889872070034174)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8aff97d8-ca2e-4b5c-97f0-7f27be5bb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, offsets, labels) in enumerate(valid_dataloader):\n",
    "            predictions = model(inputs, offsets)\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss)\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "004ad878-4f16-4645-bad5-03b31ef911fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ffaea2ef-dfa6-42d8-9804-f6649a0dbb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8608, tensor(0.3499))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_acc, eval_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dcd1c3-4a9e-486f-aae0-5e2fba620835",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d3afdd72-3320-4d13-bef3-8276445c43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  233 batches | accuracy    0.684\n",
      "| epoch   1 |   100/  233 batches | accuracy    0.796\n",
      "| epoch   1 |   150/  233 batches | accuracy    0.827\n",
      "| epoch   1 |   200/  233 batches | accuracy    0.842\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time:  1.20s | Train Accuracy    0.834 | Train Loss    0.458 | Valid Accuracy    0.811 | Valid Loss    0.416 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    50/  233 batches | accuracy    0.852\n",
      "| epoch   2 |   100/  233 batches | accuracy    0.852\n",
      "| epoch   2 |   150/  233 batches | accuracy    0.859\n",
      "| epoch   2 |   200/  233 batches | accuracy    0.860\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time:  1.09s | Train Accuracy    0.863 | Train Loss    0.361 | Valid Accuracy    0.843 | Valid Loss    0.376 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    50/  233 batches | accuracy    0.865\n",
      "| epoch   3 |   100/  233 batches | accuracy    0.872\n",
      "| epoch   3 |   150/  233 batches | accuracy    0.875\n",
      "| epoch   3 |   200/  233 batches | accuracy    0.872\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time:  1.11s | Train Accuracy    0.866 | Train Loss    0.336 | Valid Accuracy    0.871 | Valid Loss    0.349 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    50/  233 batches | accuracy    0.873\n",
      "| epoch   4 |   100/  233 batches | accuracy    0.870\n",
      "| epoch   4 |   150/  233 batches | accuracy    0.875\n",
      "| epoch   4 |   200/  233 batches | accuracy    0.876\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time:  1.21s | Train Accuracy    0.886 | Train Loss    0.324 | Valid Accuracy    0.868 | Valid Loss    0.346 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    50/  233 batches | accuracy    0.878\n",
      "| epoch   5 |   100/  233 batches | accuracy    0.882\n",
      "| epoch   5 |   150/  233 batches | accuracy    0.880\n",
      "| epoch   5 |   200/  233 batches | accuracy    0.877\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time:  1.65s | Train Accuracy    0.881 | Train Loss    0.315 | Valid Accuracy    0.866 | Valid Loss    0.352 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    50/  233 batches | accuracy    0.875\n",
      "| epoch   6 |   100/  233 batches | accuracy    0.890\n",
      "| epoch   6 |   150/  233 batches | accuracy    0.879\n",
      "| epoch   6 |   200/  233 batches | accuracy    0.886\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time:  1.43s | Train Accuracy    0.887 | Train Loss    0.308 | Valid Accuracy    0.874 | Valid Loss    0.346 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    50/  233 batches | accuracy    0.890\n",
      "| epoch   7 |   100/  233 batches | accuracy    0.885\n",
      "| epoch   7 |   150/  233 batches | accuracy    0.882\n",
      "| epoch   7 |   200/  233 batches | accuracy    0.882\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time:  1.53s | Train Accuracy    0.885 | Train Loss    0.303 | Valid Accuracy    0.871 | Valid Loss    0.339 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    50/  233 batches | accuracy    0.887\n",
      "| epoch   8 |   100/  233 batches | accuracy    0.884\n",
      "| epoch   8 |   150/  233 batches | accuracy    0.890\n",
      "| epoch   8 |   200/  233 batches | accuracy    0.888\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time:  1.12s | Train Accuracy    0.885 | Train Loss    0.299 | Valid Accuracy    0.865 | Valid Loss    0.345 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    50/  233 batches | accuracy    0.889\n",
      "| epoch   9 |   100/  233 batches | accuracy    0.888\n",
      "| epoch   9 |   150/  233 batches | accuracy    0.883\n",
      "| epoch   9 |   200/  233 batches | accuracy    0.895\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time:  1.15s | Train Accuracy    0.892 | Train Loss    0.295 | Valid Accuracy    0.858 | Valid Loss    0.356 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    50/  233 batches | accuracy    0.894\n",
      "| epoch  10 |   100/  233 batches | accuracy    0.891\n",
      "| epoch  10 |   150/  233 batches | accuracy    0.887\n",
      "| epoch  10 |   200/  233 batches | accuracy    0.896\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time:  1.15s | Train Accuracy    0.882 | Train Loss    0.292 | Valid Accuracy    0.861 | Valid Loss    0.350 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_class = len(set(train_df_vi['label']))\n",
    "vocab_size = len(vocabulary)\n",
    "embed_dim = 100\n",
    "model = TextClassificationModel(vocab_size, embed_dim, num_class).to(device)\n",
    "\n",
    "learning_rate = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc, train_loss = train(model, optimizer, criterion, train_dataloader, epoch)\n",
    "    eval_acc, eval_loss = evaluate(model, criterion, valid_dataloader)\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6f6fc-c371-47d9-89e1-e3edcbd2c30d",
   "metadata": {},
   "source": [
    "## 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "811965a0-5824-4134-9d2b-4470fb52edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dfd90217-2231-4826-b31c-0492f1c4e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        encoded = torch.tensor(vocabulary(tokenizer(text)))\n",
    "        output = model(encoded, torch.tensor([0]))\n",
    "        return output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fc392d0a-7973-403c-a9bd-245a301eb86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence               Qun ny kh l ni_ting nay mi c dp gh t...\n",
       "label                                                                  0\n",
       "preprocess_sentence    qun ny kh l ni ting nay mi c dp gh t...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ba51fcca-39ec-48a3-abf5-19ab12eb56db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_df.iloc[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ac0182a8-b49d-479f-9919-d5430c63ef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8673)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy on test set\n",
    "\n",
    "predictions, labels = [], []\n",
    "for index, row in test_df.iterrows():\n",
    "    sentence = row['preprocess_sentence']\n",
    "    label = row['label']\n",
    "    prediction = predict(sentence)\n",
    "    predictions.append(prediction)\n",
    "    labels.append(label)\n",
    "\n",
    "sum(torch.tensor(predictions) == torch.tensor(labels))/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902bf0d-5c02-46df-b9a0-7e9618023008",
   "metadata": {},
   "source": [
    "## 8. Compare: BoW, TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aedc0e-b14e-43eb-b180-750f80bce063",
   "metadata": {},
   "source": [
    "### 8.1. BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "70bc86ab-5f09-4e36-9fd7-58cdc2cf9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a4520721-5e77-4c4a-930e-30741d386859",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_df_vi['label'].tolist())\n",
    "test_labels = np.array(test_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b7420c97-6808-4855-b5f1-a16991b95161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "max_features = 10000\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "\n",
    "train_sequences = vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
    "test_sequences = vectorizer.transform(test_df['preprocess_sentence'])\n",
    "vocab_size = len(vectorizer.vocabulary_)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b3000c81-bf85-4670-aa13-c62b622d7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\basicNLPAIO\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_sequences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "722d22cf-b496-45ed-8f37-366e7d1c876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(test_sequences, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e3c7e-68f4-4385-aa89-8e24faaa2ca8",
   "metadata": {},
   "source": [
    "### 8.2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7e21609e-d01b-47df-8831-c4ab491e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "max_features = 10000\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "train_sequences = tfidf_vectorizer.fit_transform(train_df_vi['preprocess_sentence'])\n",
    "test_sequences = tfidf_vectorizer.transform(test_df['preprocess_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6cab5bb3-c33d-49c5-8272-0a1ad69b683f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_sequences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cfc0ff6c-cfab-4c92-b6cc-69d89fe81be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(test_sequences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254fb68-99c2-421f-8ac3-fc451e64e3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
